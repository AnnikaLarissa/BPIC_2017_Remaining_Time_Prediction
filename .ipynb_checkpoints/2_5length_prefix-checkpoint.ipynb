{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook filters the data and saves training and test data in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "\n",
    "# import pm4py library to work with XES logs and process mining\n",
    "import pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\envs\\processMining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 31509/31509 [00:31<00:00, 988.71it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>EventOrigin</th>\n",
       "      <th>EventID</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:LoanGoal</th>\n",
       "      <th>case:ApplicationType</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:RequestedAmount</th>\n",
       "      <th>FirstWithdrawalAmount</th>\n",
       "      <th>NumberOfTerms</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>MonthlyCost</th>\n",
       "      <th>Selected</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>OfferedAmount</th>\n",
       "      <th>OfferID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>A_Create Application</td>\n",
       "      <td>Application</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>complete</td>\n",
       "      <td>2016-01-01 09:51:15.304000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statechange</td>\n",
       "      <td>User_1</td>\n",
       "      <td>A_Submitted</td>\n",
       "      <td>Application</td>\n",
       "      <td>ApplState_1582051990</td>\n",
       "      <td>complete</td>\n",
       "      <td>2016-01-01 09:51:15.352000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1298499574</td>\n",
       "      <td>schedule</td>\n",
       "      <td>2016-01-01 09:51:15.774000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deleted</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Handle leads</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1673366067</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>2016-01-01 09:52:36.392000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Created</td>\n",
       "      <td>User_1</td>\n",
       "      <td>W_Complete application</td>\n",
       "      <td>Workflow</td>\n",
       "      <td>Workitem_1493664571</td>\n",
       "      <td>schedule</td>\n",
       "      <td>2016-01-01 09:52:36.403000+00:00</td>\n",
       "      <td>Existing loan takeover</td>\n",
       "      <td>New credit</td>\n",
       "      <td>Application_652823628</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Action org:resource            concept:name  EventOrigin  \\\n",
       "0      Created       User_1    A_Create Application  Application   \n",
       "1  statechange       User_1             A_Submitted  Application   \n",
       "2      Created       User_1          W_Handle leads     Workflow   \n",
       "3      Deleted       User_1          W_Handle leads     Workflow   \n",
       "4      Created       User_1  W_Complete application     Workflow   \n",
       "\n",
       "                 EventID lifecycle:transition  \\\n",
       "0  Application_652823628             complete   \n",
       "1   ApplState_1582051990             complete   \n",
       "2    Workitem_1298499574             schedule   \n",
       "3    Workitem_1673366067             withdraw   \n",
       "4    Workitem_1493664571             schedule   \n",
       "\n",
       "                    time:timestamp           case:LoanGoal  \\\n",
       "0 2016-01-01 09:51:15.304000+00:00  Existing loan takeover   \n",
       "1 2016-01-01 09:51:15.352000+00:00  Existing loan takeover   \n",
       "2 2016-01-01 09:51:15.774000+00:00  Existing loan takeover   \n",
       "3 2016-01-01 09:52:36.392000+00:00  Existing loan takeover   \n",
       "4 2016-01-01 09:52:36.403000+00:00  Existing loan takeover   \n",
       "\n",
       "  case:ApplicationType      case:concept:name  case:RequestedAmount  \\\n",
       "0           New credit  Application_652823628               20000.0   \n",
       "1           New credit  Application_652823628               20000.0   \n",
       "2           New credit  Application_652823628               20000.0   \n",
       "3           New credit  Application_652823628               20000.0   \n",
       "4           New credit  Application_652823628               20000.0   \n",
       "\n",
       "   FirstWithdrawalAmount  NumberOfTerms Accepted  MonthlyCost Selected  \\\n",
       "0                    NaN            NaN      NaN          NaN      NaN   \n",
       "1                    NaN            NaN      NaN          NaN      NaN   \n",
       "2                    NaN            NaN      NaN          NaN      NaN   \n",
       "3                    NaN            NaN      NaN          NaN      NaN   \n",
       "4                    NaN            NaN      NaN          NaN      NaN   \n",
       "\n",
       "   CreditScore  OfferedAmount OfferID  \n",
       "0          NaN            NaN     NaN  \n",
       "1          NaN            NaN     NaN  \n",
       "2          NaN            NaN     NaN  \n",
       "3          NaN            NaN     NaN  \n",
       "4          NaN            NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pm4py.read_xes(\"data/BPI_Challenge_2017.xes.gz\")\n",
    "log_df = pm4py.convert_to_dataframe(log)\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event index in trace\n",
    "\n",
    "We add to each event in the log its position in their trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column \"event_index_in_trace\"\n",
    "# which indicates the 1st, 2nd ... event in the trace\n",
    "log_df = log_df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"])\n",
    "log_df[\"event_index_in_trace\"] = log_df.groupby(\"case:concept:name\").cumcount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining time\n",
    "\n",
    "Here we calculate the remaining time per trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which indicates time from that event until the last event in the trace\n",
    "log_df[\"time:timestamp\"] = pd.to_datetime(log_df[\"time:timestamp\"], utc=True)\n",
    "log_df[\"remaining_time\"] = log_df.groupby(\"case:concept:name\")[\"time:timestamp\"].transform(lambda x: x.max() - x).dt.total_seconds() / (24 * 60 * 60)  # convert to float days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time being executed\n",
    "\n",
    "We also will store the time that the trace is being executed from the first event in the trace until the current event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df[\"time:timestamp\"] = pd.to_datetime(log_df[\"time:timestamp\"], utc=True)\n",
    "\n",
    "# Time in execution: time that has been the trace in execution from the first event\n",
    "log_df[\"execution_time\"] = log_df.groupby(\"case:concept:name\")[\"time:timestamp\"].transform(lambda x: x - x.min()).dt.total_seconds() / (24 * 60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the data 5 prefix length\n",
    "\n",
    "The idea is to construct a database with traces of length 5. The information is gathered by joinning the 5 events of traces that happens following to each other until the end of the trace. For that we need to filter the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pm4py.filter_case_size(log_df, 5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10600\\372152058.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\processMining\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m-> 9864\u001b[1;33m     def apply(\n\u001b[0m\u001b[0;32m   9865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9866\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAggFuncType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9867\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for id, trace in log_df.groupby(\"case:concept:name\"):\n",
    "\n",
    "    groups = [trace.iloc[i:i+window_size] for i in range(len(trace) - window_size + 1)]\n",
    "\n",
    "    for group in groups:\n",
    "        group = group.apply(lambda row: row.tolist(), axis=1)\n",
    "        result_df = pd.concat([result_df, group], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test\n",
    "\n",
    "Using the pm4py.split_train_test resulted in traces in train that ended after the start of traces in test unfortunately. This is not a good split, so we implement it manually by sorting traces on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"])\n",
    "trace_start_df = log_df[[\"case:concept:name\", \"time:timestamp\"]].groupby([\"case:concept:name\"]).min()\n",
    "trace_end_df = log_df[[\"case:concept:name\", \"time:timestamp\"]].groupby([\"case:concept:name\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last 10% of the traces as test set\n",
    "test_size = round(len(trace_start_df)*0.1)\n",
    "test_cases = trace_start_df.sort_values(\"time:timestamp\").tail(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cases must end before test cases start\n",
    "train_cases = trace_end_df[trace_end_df[\"time:timestamp\"] < test_cases[\"time:timestamp\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = log_df[log_df[\"case:concept:name\"].isin(train_cases.index)]\n",
    "test_df = log_df[log_df[\"case:concept:name\"].isin(test_cases.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that the timestamps don't overlap\n",
    "# all traces in train must end before the start of traces in test\n",
    "print(train_df[\"time:timestamp\"].max())\n",
    "print(test_df[\"time:timestamp\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding\n",
    "\n",
    "For now we use the basic feature encoding from pm4py, but we want to experiment with using complex index encoding, where we encode the previous 10 activities (or add padding). Furthermore, we add the index of the activity in the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features we are going to encode\n",
    "columns_to_encode = ['Action', 'concept:name', 'case:LoanGoal']\n",
    "\n",
    "# one-hot encode the data\n",
    "train_df_encode = pd.get_dummies(train_df[columns_to_encode], dtype=int)\n",
    "test_df_encode = pd.get_dummies(test_df[columns_to_encode], dtype=int)\n",
    "test_df_encode.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['org:resource', 'EventOrigin', 'EventID',\n",
    "       'lifecycle:transition', 'time:timestamp',\n",
    "       'case:ApplicationType', 'case:concept:name', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'MonthlyCost',\n",
    "       'Selected', 'CreditScore', 'OfferedAmount',\n",
    "       'event_index_in_trace', 'remaining_time', 'execution_time']\n",
    "\n",
    "# Concatenate the DataFrames based on the index\n",
    "full_train_df = pd.concat([train_df[columns_to_keep], train_df_encode], axis=1)\n",
    "full_test_df = pd.concat([test_df[columns_to_keep], test_df_encode], axis=1)\n",
    "\n",
    "full_train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features X and targets y of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the one-hot encoded dataframes\n",
    "X_train = full_train_df.drop(columns=[\"remaining_time\"])\n",
    "X_train.to_csv(\"data/generated/onehot/X_train.csv\")\n",
    "\n",
    "X_test = full_test_df.drop(columns=[\"remaining_time\"])\n",
    "X_test.to_csv(\"data/generated/onehot/X_test.csv\")\n",
    "\n",
    "y_train = full_train_df[\"remaining_time\"]\n",
    "y_train.to_csv(\"data/generated/onehot/y_train.csv\")\n",
    "\n",
    "y_test = full_test_df[\"remaining_time\"]\n",
    "y_test.to_csv(\"data/generated/onehot/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency encoding and save train test files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency encoding for test and train df\n",
    "# Select columns that start with \"concept:\" or \"Action_\"\n",
    "relevant_columns = [c for c in train_df_encode.columns if c.startswith(\"concept:\") or c.startswith(\"Action_\")]\n",
    "\n",
    "for trace_id, trace_df in full_train_df.groupby(\"case:concept:name\"):\n",
    "    trace_df_sorted = trace_df.sort_values(by='event_index_in_trace')\n",
    "    # Update only the selected columns with the cumulative sum\n",
    "    full_train_df.loc[trace_df_sorted.index, relevant_columns] = trace_df_sorted[relevant_columns].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that start with \"concept:\" or \"Action_\"\n",
    "relevant_columns = [c for c in test_df_encode.columns if c.startswith(\"concept:\") or c.startswith(\"Action_\")]\n",
    "\n",
    "for trace_id, trace_df in full_test_df.groupby(\"case:concept:name\"):\n",
    "    trace_df_sorted = trace_df.sort_values(by='event_index_in_trace')\n",
    "    # Update only the selected columns with the cumulative sum\n",
    "    full_test_df.loc[trace_df_sorted.index, relevant_columns] = trace_df_sorted[relevant_columns].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features X and targets y of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the frequency encoded dataframes\n",
    "X_train = full_train_df.drop(columns=[\"remaining_time\"])\n",
    "X_train.to_csv(\"data/generated/frequency/X_train.csv\")\n",
    "\n",
    "X_test = full_test_df.drop(columns=[\"remaining_time\"])\n",
    "X_test.to_csv(\"data/generated/frequency/X_test.csv\")\n",
    "\n",
    "y_train = full_train_df[\"remaining_time\"]\n",
    "y_train.to_csv(\"data/generated/frequency/y_train.csv\")\n",
    "\n",
    "y_test = full_test_df[\"remaining_time\"]\n",
    "y_test.to_csv(\"data/generated/frequency/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
